NFS配置
引用了超全的NFS文档(FOR LINUX) 一文

一：服务器端的设定（以LINUX为例） 
服务器端的设定都是在/etc/exports这个文件中进行设定的，设定格式如下： 
欲分享出去的目录 主机名称1或者IP1(参数1，参数2） 主机名称2或者IP2（参数3，参数4） 
上面这个格式表示，同一个目录分享给两个不同的主机，但提供给这两台主机的权限和参数是不同的，所以分别设定两个主机得到的权限。 
可以设定的参数主要有以下这些： 
rw：可读写的权限； 
ro：只读的权限； 
no_root_squash：登入到NFS主机的用户如果是ROOT用户，他就拥有ROOT的权限，此参数很不安全，建议不要使用。 
root_squash：在登入 NFS 主機使用分享之目錄的使用者如果是 root 時，那麼這個使用者的權限將被壓縮成為匿名使用者，通常他的 UID 與 GID 都會變成 nobody 那個身份； 
all_squash：不管登陆NFS主机的用户是什么都会被重新设定为nobody。 
anonuid：将登入NFS主机的用户都设定成指定的user id,此ID必须存在于/etc/passwd中。 
anongid：同 anonuid ，但是變成 group ID 就是了！ 
sync：资料同步写入存储器中。 
async：资料会先暂时存放在内存中，不会直接写入硬盘。 
insecure 允许从这台机器过来的非授权访问。
例如可以编辑/etc/exports为： 
/tmp　　　　　*(rw,no_root_squash) 
/home/public　192.168.0.*(rw)　　 *(ro) 
/home/test　　192.168.0.100(rw) 
/home/linux　 *.the9.com(rw,all_squash,anonuid=40,anongid=40) 
设定好后可以使用以下命令启动NFS: 
/etc/rc.d/init.d/portmap start (在REDHAT中PORTMAP是默认启动的） 
/etc/rc.d/init.d/nfs start
exportfs命令： 
如果我们在启动了NFS之后又修改了/etc/exports，是不是还要重新启动nfs呢？这个时候我们就可以用exportfs命令来使改动立刻生效，该命令格式如下： 
exportfs [-aruv] 
-a ：全部mount或者unmount /etc/exports中的内容 
-r ：重新mount /etc/exports中分享出来的目录 
-u ：umount 目录 
-v ：在 export 的時候，将详细的信息输出到屏幕上。 
具体例子： 
[root @test root]# exportfs -rv <==全部重新 export 一次！ 
exporting 192.168.0.100:/home/test 
exporting 192.168.0.*:/home/public 
exporting *.the9.com:/home/linux 
exporting *:/home/public 
exporting *:/tmp 
reexporting 192.168.0.100:/home/test to kernel
exportfs -au <==全部都卸载了。
二、客户端的操作： 
1、showmout命令对于NFS的操作和查错有很大的帮助，所以我们先来看一下showmount的用法 
showmout 
-a ：这个参数是一般在NFS SERVER上使用，是用来显示已经mount上本机nfs目录的cline机器。 
-e ：显示指定的NFS SERVER上export出来的目录。 
例如： 
showmount -e 192.168.0.30 
Export list for localhost: 
/tmp * 
/home/linux *.linux.org 
/home/public (everyone) 
/home/test 192.168.0.100 
2、mount nfs目录的方法： 
mount前先检查一下nfs客户端的一些所需服务是否启动
service nfs status 若没有运行则：
service portmap start
service nfs start
若成功启动则进行挂载： 
mount -t nfs hostname(orIP):/directory /mount/point 
具体例子： 
Linux: mount -t nfs 192.168.0.1:/tmp /mnt/nfs 
Solaris:mount -F nfs 192.168.0.1:/tmp /mnt/nfs 
BSD: mount 192.168.0.1:/tmp /mnt/nfs
3、mount nfs的其它可选参数： 
HARD mount和SOFT MOUNT： 
HARD: NFS CLIENT会不断的尝试与SERVER的连接（在后台，不会给出任何提示信息,在LINUX下有的版本仍然会给出一些提示），直到MOUNT上。 
SOFT:会在前台尝试与SERVER的连接，是默认的连接方式。当收到错误信息后终止mount尝试，并给出相关信息。 
例如：mount -F nfs -o hard 192.168.0.10:/nfs /nfs 
对于到底是使用hard还是soft的问题，这主要取决于你访问什么信息有关。例如你是想通过NFS来运行X PROGRAM的话，你绝对不会希望由于一些意外的情况（如网络速度一下子变的很慢，插拔了一下网卡插头等）而使系统输出大量的错误信息，如果此时你用的是HARD方式的话，系统就会等待，直到能够重新与NFS SERVER建立连接传输信息。另外如果是非关键数据的话也可以使用SOFT方式，如FTP数据等，这样在远程机器暂时连接不上或关闭时就不会挂起你的会话过程。
rsize和wsize： 
文件传输尺寸设定：V3没有限定传输尺寸，V2最多只能设定为8k，可以使用-rsize and -wsize 来进行设定。这两个参数的设定对于NFS的执行效能有较大的影响 
bg：在执行mount时如果无法顺利mount上时，系统会将mount的操作转移到后台并继续尝试mount，直到mount成功为止。（通常在设定/etc/fstab文件时都应该使用bg，以避免可能的mount不上而影响启动速度） 
fg：和bg正好相反，是默认的参数 
nfsvers＝n:设定要使用的NFS版本，默认是使用2，这个选项的设定还要取决于server端是否支持NFS VER 3 
mountport：设定mount的端口 
port：根据server端export出的端口设定，例如如果server使用5555端口输出NFS,那客户端就需要使用这个参数进行同样的设定 
timeo=n:设置超时时间，当数据传输遇到问题时，会根据这个参数尝试进行重新传输。默认值是7/10妙（0.7秒）。如果网络连接不是很稳定的话就要加大这个数值，并且推荐使用HARD MOUNT方式，同时最好也加上INTR参数，这样你就可以终止任何挂起的文件访问。 
intr 允许通知中断一个NFS调用。当服务器没有应答需要放弃的时候有用处。 
udp：使用udp作为nfs的传输协议（NFS V2只支持UDP) 
tcp：使用tcp作为nfs的传输协议 
namlen=n：设定远程服务器所允许的最长文件名。这个值的默认是255 
acregmin=n：设定最小的在文件更新之前cache时间，默认是3 
acregmax=n：设定最大的在文件更新之前cache时间，默认是60 
acdirmin=n：设定最小的在目录更新之前cache时间，默认是30 
acdirmax=n：设定最大的在目录更新之前cache时间，默认是60 
actimeo=n：将acregmin、acregmax、acdirmin、acdirmax设定为同一个数值，默认是没有启用。 
retry=n：设定当网络传输出现故障的时候，尝试重新连接多少时间后不再尝试。默认的数值是10000 minutes 
noac:关闭cache机制。 
同时使用多个参数的方法：mount -t nfs -o timeo=3,udp,hard 192.168.0.30:/tmp /nfs 
请注意，NFS客户机和服务器的选项并不一定完全相同，而且有的时候会有冲突。比如说服务器以只读的方式导出，客户端却以可写的方式mount,虽然可以成功mount上，但尝试写入的时候就会发生错误。一般服务器和客户端配置冲突的时候，会以服务器的配置为准。

4、/etc/fstab的设定方法 
/etc/fstab的格式如下： 
fs_spec　　　fs_file　　fs_type　　　fs_options　　fs_dump　fs_pass　 
fs_spec:该字段定义希望加载的文件系统所在的设备或远程文件系统,对于nfs这个参数一般设置为这样：192.168.0.1:/NFS 
fs_file:本地的挂载点 
fs_type：对于NFS来说这个字段只要设置成nfs就可以了 
fs_options:挂载的参数，可以使用的参数可以参考上面的mount参数。 
fs_dump　-　该选项被"dump"命令使用来检查一个文件系统应该以多快频率进行转储，若不需要转储就设置该字段为0 
fs_pass　-　该字段被fsck命令用来决定在启动时需要被扫描的文件系统的顺序，根文件系统"/"对应该字段的值应该为1，其他文件系统应该为2。若该文件系统无需在启动时扫描则设置该字段为0 。
5、与NFS有关的一些命令介绍 
nfsstat: 
查看NFS的运行状态，对于调整NFS的运行有很大帮助 
rpcinfo： 
查看rpc执行信息，可以用于检测rpc运行情况的工具。
三、NFS启动设置

为使下次重起时系统能自动启动portmap和nfs进程.在客户端和服务端都要执行.

#chkconfig –level 235 portmap on

#chkconfig –level 235 nfs on

为了客户端下次重起时能自动连接server端的nfs分区.修改客户端/etc/fstab文件.添加

/wyl 192.168.0.5:/disk0

四、NFS调优 
调优的步骤： 
1、测量当前网络、服务器和每个客户端的执行效率。 
2、分析收集来的数据并画出图表。查找出特殊情况，例如很高的磁盘和CPU占用、已经高的磁盘使用时间 
3、调整服务器 
4、重复第一到第三步直到达到你渴望的性能

与NFS性能有关的问题有很多，通常可以要考虑的有以下这些选择：
WSIZE,RSIZE参数来优化NFS的执行效能 
WSIZE、RSIZE对于NFS的效能有很大的影响。 
wsize和rsize设定了SERVER和CLIENT之间往来数据块的大小，这两个参数的合理设定与很多方面有关，不仅是软件方面也有硬件方面的因素会影响这两个参数的设定（例如LINUX KERNEL、网卡，交换机等等）。 
下面这个命令可以测试NFS的执行效能，读和写的效能可以分别测试，分别找到合适的参数。对于要测试分散的大量的数据的读写可以通过编写脚本来进行测试。在每次测试的时候最好能重复的执行一次MOUNT和unmount。 
time dd if=/dev/zero of=/mnt/home/testfile bs=16k count=16384 
用于测试的WSIZE,RSIZE最好是1024的倍数，对于NFS V2来说8192是RSIZE和WSIZE的最大数值，如果使用的是NFS V3则可以尝试的最大数值是32768。 
如果设置的值比较大的时候，应该最好在CLIENT上进入mount上的目录中，进行一些常规操作（LS,VI等等），看看有没有错误信息出现。有可能出现的典型问题有LS的时候文件不能完整的列出或者是出现错误信息，不同的操作系统有不同的最佳数值，所以对于不同的操作系统都要进行测试。
设定最佳的NFSD的COPY数目。 
linux中的NFSD的COPY数目是在/etc/rc.d/init.d/nfs这个启动文件中设置的，默认是8个NFSD,对于这个参数的设置一般是要根据可能的CLIENT数目来进行设定的，和WSIZE、RSIZE一样也是要通过测试来找到最近的数值。
UDP and TCP 
可以手动进行设置，也可以自动进行选择。 
mount -t nfs -o sync,tcp,noatime,rsize=1024,wsize=1024 EXPORT_MACHINE:/EXPORTED_DIR /DIR 
UDP有着传输速度快，非连接传输的便捷特性，但是UDP在传输上没有TCP来的稳定，当网络不稳定或者黑客入侵的时候很容易使NFS的 Performance 大幅降低甚至使网络瘫痪。所以对于不同情况的网络要有针对的选择传输协议。nfs over tcp比较稳定，nfs over udp速度较快。在机器较少网络状况较好的情况下使用UDP协议能带来较好的性能，当机器较多，网络情况复杂时推荐使用TCP协议（V2只支持UDP协议）。在局域网中使用UDP协议较好，因为局域网有比较稳定的网络保证，使用UDP可以带来更好的性能，在广域网中推荐使用TCP协议，TCP协议能让NFS在复杂的网络环境中保持最好的传输稳定性。可以参考这篇文章：[url]http://www.hp.com.tw/ssn/unix/0212/unix021204.asp[/url]
版本的选择 
V3作为默认的选择（RED HAT 8默认使用V2,SOLARIS 8以上默认使用V3），可以通过vers= mount option来进行选择。 
LINUX通过mount option的nfsvers=n进行选择。
五、NFS故障解决 
1、NFSD没有启动起来 
首先要确认 NFS 输出列表存在，否则 nfsd 不会启动。可用 exportfs 命令来检查，如果 exportfs 命令没有结果返回或返回不正确，则需要检查 /etc/exports 文件。 
2、mountd 进程没有启动 
mountd 进程是一个远程过程调用 (RPC) ，其作用是对客户端要求安装（mount）文件系统的申请作出响应。mountd进程通过查找 /etc/xtab文件来获知哪些文件系统可以被远程客户端使用。另外，通过mountd进程，用户可以知道目前有哪些文件系统已被远程文件系统装配，并得知远程客户端的列表。查看mountd是否正常启动起来可以使用命令rpcinfo进行查看，在正常情况下在输出的列表中应该象这样的行： 
100005 1 udp 1039 mountd 
100005 1 tcp 1113 mountd 
100005 2 udp 1039 mountd 
100005 2 tcp 1113 mountd 
100005 3 udp 1039 mountd 
100005 3 tcp 1113 mountd 
如果没有起来的话可以检查是否安装了PORTMAP组件。 
rpm -qa|grep portmap 
3、fs type nfs no supported by kernel 
kernel不支持nfs文件系统，重新编译一下KERNEL就可以解决。 
4、cant contact portmapper: RPC: Remote system error - Connection refused 
出现这个错误信息是由于SEVER端的PORTMAP没有启动。 
5、mount clntudp_create: RPC: Program not registered 
NFS没有启动起来，可以用showmout -e host命令来检查NFS SERVER是否正常启动起来。 
6、mount: localhost:/home/test failed, reason given by server: Permission denied 
这个提示是当client要mount nfs server时可能出现的提示，意思是说本机没有权限去mount nfs server上的目录。解决方法可以参考以下网友的帖子，我试了一下，确实有效。

***********************************************
在网上查了一些资料，有人说把/etc/exports换成域名试试，所以我就改成了：
[root@ha1 nfs]# cat /etc/exports
/nfs/mp3/mp3files *.xxxxxx.com(rw,async)

再mount，发现正常，没有问题了。

后来又查了一些相关资料，才知道：

nfs server接到客户端的mount时，会先客户的IP做反解成域名，用域名(注意是用域名而不是ＩＰ)去和/etc/exports做比较，如果匹配不成功会失败。

而我做了域名反解后，并没有更新/etc/exports内的ＩＰ为域名。所以匹配不到对应的域名，自然就出现mount: 192.168.1.172:/nfs/mp3/mp3files failed, reason given by server: Permission denied的错误了。
之前用ＩＰ没有问题是因为在域名不能反解的时候还是用ＩＰ去匹配的
********************************************************
关于这个问题，还有一个导致这个问题产生的原因。
当时，我们的服务器有两块网卡，一个内网，一个外网。我们的主机域名是和外网绑定的。但是NFS Server 机器是内网的一个server充当的。所以每次它都会从内网网卡来访问我这台服务器，而这台服务器指定的是外网（另一块网卡），所以总是提示没有授权。解决办法，在NFS Server端，更改/etc/exports文件的内容，指定IP为内网IP即可。可以用tail -f /var/log/messages查看日志：
Mar 16 14:25:02 osg mountd[26400]: refused mount request from 159.226.13.52 for /disk2/osg/app (/disk2/osg/app): unmatched host

****************************************************
7、被防火墙阻挡 
这个原因很多人都忽视了，在有严格要求的网络环境中，我们一般会关闭linux上的所有端口，当需要使用哪个端口的时候才会去打开。而NFS默认是使用111端口，所以我们先要检测是否打开了这个端口，另外也要检查TCP_Wrappers的设定。

8.umount 的时候报错:device is busy(http://liuyu.blog.51cto.com/183345/64044)
执行umount 的时候却提示:device is busy  
强行: umount /dev/sdb2 -f
提示:umount2: 设备或资源忙
umount: /mnt/usbdisk: device is busy
 
有人在使用...查看一样使用情况: fuser -m /mnt/usbdisk    
有 6406 进程在使用..
ps aux | grep 6406
再kill
 
接着umount 提示还是失败...
接着 fuser -k /mnt/usbdisk
提示:
/mnt/usbdisk/:        6406c
No automatic removal. Please use  umount /mnt/usbdisk
按提示操作: umount /mnt/usbdisk  OK    搞定!

8.命令失效：

所有service nfs start/stop/status.....都不能运行，包括service portmap start/stop/status.....都不能运行, this greatly distress me.

 

sollution:

 ps aux |grep nfs

kill -9 2001 2002 2003

 setup , and then unticking the nfs services  (nfsd, netfile, portmap..)

# The above step is to prevent nfs start when os begin to run .

reboot：

service portmap start

service nfs start

9.Permission denied

查看nfs server的/var/log/message:
Mar 30 14:53:07 sysimages mountd[6936]: Cannot export /panfs, possibly unsupported filesystem or fsid= required
Mar 30 14:54:04 sysimages kernel: Removing netfilter NETLINK layer.

在NFS server的 /etc/exports文件里做如下改动 fsid = 0：

/sdc                           *(rw,insecure,sync,insecure_locks,no_root_squash)
/panfs                           *(fsid=0,rw,insecure,sync,insecure_locks,no_root_squash)

六、NFS安全 
NFS的不安全性主要体现于以下4个方面:
1、新手对NFS的访问控制机制难于做到得心应手,控制目标的精确性难以实现 
2、NFS没有真正的用户验证机制,而只有对RPC/Mount请求的过程验证机制 
3、较早的NFS可以使未授权用户获得有效的文件句柄 
4、在RPC远程调用中,一个SUID的程序就具有超级用户权限.
加强NFS安全的方法： 
1、合理的设定/etc/exports中共享出去的目录，最好能使用anonuid，anongid以使MOUNT到NFS SERVER的CLIENT仅仅有最小的权限，最好不要使用root_squash。 
2、使用IPTABLE防火墙限制能够连接到NFS SERVER的机器范围 
iptables -A INPUT -i eth0 -p TCP -s 192.168.0.0/24 --dport 111 -j ACCEPT 
iptables -A INPUT -i eth0 -p UDP -s 192.168.0.0/24 --dport 111 -j ACCEPT 
iptables -A INPUT -i eth0 -p TCP -s 140.0.0.0/8 --dport 111 -j ACCEPT 
iptables -A INPUT -i eth0 -p UDP -s 140.0.0.0/8 --dport 111 -j ACCEPT 
3、为了防止可能的Dos攻击，需要合理设定NFSD 的COPY数目。 
4、修改/etc/hosts.allow和/etc/hosts.deny达到限制CLIENT的目的 
/etc/hosts.allow 
portmap: 192.168.0.0/255.255.255.0 : allow 
portmap: 140.116.44.125 : allow
/etc/hosts.deny 
portmap: ALL : deny 
5、改变默认的NFS 端口 
NFS默认使用的是111端口，但同时你也可以使用port参数来改变这个端口，这样就可以在一定程度上增强安全性。 
6、使用Kerberos V5作为登陆验证系统
七、用户权限
http://sns.linuxpk.com/space-52196-do-blog-id-16120.html

client挂载上主机的一个目录以后，它对这个目录拥有上面样子的权限呢？这和client端的用户，服务器端的用户，以及文件/etc/exports里面的内容都是相关的，他们综合作用的结果得到client端的目录使用权限，下面以例子的形式来讲解这个问题。

假设/etc/exports里面的内容为

/tmp *(rw,no_root_squash)

/home/public 192.168.0.*(rw) *(ro)

/home/test 192.168.0.100(rw)

/home/linux *.linux.org(rw,all_squash,anonuid=40,anongid=40)

假设我们在192.168.0.100这个client端登陆此NFS Server主机(192.168.0.2),那么

情况一：在192.168.0.100的帐号为test这个身份，同时NFS Server主机上也有test这个帐号时：

1. 由于NFS主机的/tmp权限为-rwxrwxrwt，所以我(test在192.168.0.100上)在/tmp下面具有存取的权限，并且写入文件的所有人为test。

2. 在/home/public中，由于我有读写的权限，如果NFS主机在/home/public这个目录的权限对于test开放写入的话，那么就可以读写，并且写入档案的所有人是test。如果NFS主机的/home/public对test这个使用者并没有开放写入权限时，那就无法写入，虽然 /etc/exports里面是rw，也不起作用。

3. 在/home/test中，权限与/home/public有相同的状态，需要NFS主机的/home/test对于test有开放的权限。

4. 在/home/linux当中，不论是何种的user,身份都会被变成UID=40的这个帐号。

    综上所述，客户端以某个用户A使用nfs server共享的目录以后，如果服务器端刚好也有这个用户A。

如果客户端用户A（普通用户）想访问的那个目录，在nfs server端刚好开放了对server端这个用户A的相应的权限，那么客户端用户A所创建的文件的所有者就是服务器端的A了。

当然这是没有其他参数的限制的情况下，在其他参数的限制条件下，如all_squash，root_squash等，则文件的创建的所有者要进行相应的改变。

 

情况二:如果我们在192.168.0.100的身份为test2,但是NFS主机却没有test2这个帐号时：

1. 在/tmp下还是可以写入，但是写入的档案所有人变成nobody。

2. 在/home/public与/home/test里面是否可以写入，还需要看/home/public的权限而定，不过身份就被变成nobody了。

3. /home/linux下的身份还是变成UID=40的帐号.

    综上所述，客户端以某个用户A使用nfs server共享的目录以后，如果服务器端刚好没有这个用户A。

    如果客户端用户A（普通用户）想访问的那个目录，在nfs server端这个目录的开启了相应的权限位，那么这个用户A的就有了相应的权限，他所创建的文件的所有者会变成nobody。如果服务器端没有开启相应的权限位，那么客户端用户A对这个目录就没有了相应的权限。

当然这是没有其他参数的限制的情况下，在其他参数的限制条件下，如all_squash，root_squash等，则文件的创建的所有者要进行相应的改变。

 

情况三:在192.168.0.100的身份为root：

1. 在/tmp里面可以写入，但是由于no_root_squash的参数，改变了预设的root_squash的设定值，所以在/tmp写入档案的所有人为root了。

2. 在/home/public底下的身份被压缩成了nobody,因为预设的属性都具有root_squash，所以档案所有人就变成了nobody。

3. /home/test情况与/home/public相同。

4. /home/linux中，root的身份也被压缩成UID=40的那个使用者了。

 

 

八、文件系统覆盖问题

ll /home/zhangsan/mntTest

total 20
-rw-r--r-- 1 root root 7 May 11 20:57 1
-rw-r--r-- 1 root root 8 May 11 20:57 2
-rw-r--r-- 1 root root 8 May 11 20:57 3
-rw-r--r-- 1 root root 8 May 11 20:57 4
-rw-r--r-- 1 root root 8 May 11 20:57 5

mount ***.***.**:/disk2/**/**/mntTest/ /home/zhangsan/mntTest/

ll /home/zhangsan/mntTest

total 16
-rw-r--r-- 1 root root 6 May 11 20:39 4
-rw-r--r-- 1 root root 6 May 11 20:40 5
-rw-r--r-- 1 root root 6 May 11 20:40 6
-rw-r--r-- 1 root root 6 May 11 20:40 7

这样做完后，把原来的目录完全替换了（临时的），先在的4、5也不是原来的4、5了

九、Mount命令的一些Tips

详见：http://blog.chinaunix.net/u1/34500/showart_2359152.html


*将文件系统中的一部分绑定挂载: 

mount --bind olddir newdir 

这里，olddir是一个已经挂载的挂载点中的某个子目录。这样操作之后，对于这个olddir，可以从挂载点的olddir进行访问，也可以从newdir进行访问，如果卸载了olddir的挂载点，newdir仍旧可以访问原来olddir的内容,想要恢复newdir原来的内容，那么就umount newdir. 


*将文件系统中的某个单个文件帮定挂载： 

mount --bind oldfile newfile 

这里，oldfile是一个已经挂载的挂载点中的某个文件。这样操作之后，对于这个oldfile，可以从挂载点的oldfile进行访问，也可以从newfile进行访问，如果卸载了oldfile的挂载点，newfile仍旧可以访问原来oldfile的内容,想要恢复newfile原来的内容，那么就umount newfile. 


*将挂载点位置移动： 

mount --move olddir newdir 

这里，原来的挂载点是olddir,我想要把挂载点更换到newdir的话，就用这个命令，这样旧有的挂载点就没有了。另外我实践插入sd卡的时候，一般linux会自动在/media/下创建一个disk目录，然后挂载上去，当卸载的时候会自动删除这个目录；但是如果使用move的话这个目录会遗留下来。 


*挂载临时文件系统： 

mount -t tmpfs tmpfs tmpfsTest/ 

这里，tmpfs是一个在内存中开辟空间的一种文件系统。这里的第2个tmpfs处实际可以是任意字符串。例如："mount -t tmpfs tmphahaha tmpfsTest/"之后，我用mount |grep Test,会输出： 

tmphahaha on /home/quietheart/test/tmpfsTest type tmpfs (rw) 